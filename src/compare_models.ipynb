{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1997,"status":"ok","timestamp":1655126650698,"user":{"displayName":"松波(Matsunami)旭(Akira)","userId":"04248064094562346782"},"user_tz":-540},"id":"F6bBgw-KPeiE","outputId":"6aaa74ab-eef0-421a-d070-575f624d7b83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Initializing\n","from google.colab import drive\n","import re\n","import os\n","import math\n","import keras\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","import pathlib\n","from keras.utils import np_utils\n","import cv2\n","\n","drive.mount('/content/drive')\n","# Define constant value\n","RESEARCH_WORK_PATH = \"/content/drive/My Drive/Colab Notebooks/BachelorResearch/\"\n","MODEL_PATH = RESEARCH_WORK_PATH + \"models/\"\n","DATA_PATH = RESEARCH_WORK_PATH + \"MER_audio_taffc_dataset_wav/2s/unknown_img/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2JfLupyRLc-"},"outputs":[],"source":["def path_to_pic(dir_folder):\n","    list_of_pic = []\n","    for file in os.listdir(dir_folder):\n","        if file.endswith(\".jpg\"):\n","            directory = \"%s%s\" % (dir_folder, file)\n","            list_of_pic.append(directory)\n","    return list_of_pic\n","\n","def make_unknown_dataset(path):\n","  x = []\n","  y = []\n","  for pic in path_to_pic(path):\n","    im = np.array(Image.open(pic))\n","    x.append(im)\n","    y.append(int(pathlib.Path(pic).stem[1])-1)\n","  x = np.array(x)\n","  x = x.astype(\"float32\")\n","  x /= 255\n","  y = np.array(y)\n","  return x,y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHFM7q8RPmlZ","executionInfo":{"status":"ok","timestamp":1655126819748,"user_tz":-540,"elapsed":169051,"user":{"displayName":"松波(Matsunami)旭(Akira)","userId":"04248064094562346782"}},"outputId":"98765683-e178-42ec-be6f-698033ddb22e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[330. 349. 345. 346.]\n","[MODEL] efficient_net_v2_vanilla_crop02\n","input shape: (None, 102, 173, 3)\n","43/43 - 3s - loss: 1.1189 - accuracy: 0.5482 - 3s/epoch - 75ms/step\n","accuracy: 0.5481751561164856\n","loss: 1.1189429759979248\n","\n","[MODEL] efficient_net_v2_vanilla_crop_01\n","input shape: (None, 224, 173, 3)\n","43/43 - 4s - loss: 1.1420 - accuracy: 0.5628 - 4s/epoch - 87ms/step\n","accuracy: 0.5627737045288086\n","loss: 1.1420042514801025\n","\n","[MODEL] efficient_net_v2_vanilla_crop015\n","input shape: (None, 150, 173, 3)\n","43/43 - 3s - loss: 1.0720 - accuracy: 0.5555 - 3s/epoch - 79ms/step\n","accuracy: 0.5554744601249695\n","loss: 1.0719879865646362\n","\n","[MODEL] mnist_crop0.1\n","input shape: (None, 224, 173, 1)\n","43/43 - 1s - loss: 1.3863 - accuracy: 0.2547 - 949ms/epoch - 22ms/step\n","accuracy: 0.2547445297241211\n","loss: 1.3863213062286377\n","\n","[MODEL] mnist_crop0.15\n","input shape: (None, 150, 173, 1)\n","43/43 - 1s - loss: 1.3864 - accuracy: 0.2547 - 749ms/epoch - 17ms/step\n","accuracy: 0.2547445297241211\n","loss: 1.3863636255264282\n","\n","[MODEL] mnist_crop0.2\n","input shape: (None, 102, 173, 1)\n","43/43 - 1s - loss: 1.3862 - accuracy: 0.2526 - 585ms/epoch - 14ms/step\n","accuracy: 0.2525547444820404\n","loss: 1.3862091302871704\n","\n","[MODEL] mnist\n","input shape: (None, 257, 173, 1)\n","43/43 - 1s - loss: 1.3863 - accuracy: 0.2518 - 1s/epoch - 25ms/step\n","accuracy: 0.25182482600212097\n","loss: 1.3862918615341187\n","\n","[MODEL] VGG16\n","input shape: (None, 257, 173, 1)\n","43/43 - 3s - loss: 1.3862 - accuracy: 0.2518 - 3s/epoch - 78ms/step\n","accuracy: 0.25182482600212097\n","loss: 1.3862087726593018\n","\n","[MODEL] VGG16_crop0.1\n","input shape: (None, 224, 173, 1)\n","43/43 - 3s - loss: 1.3864 - accuracy: 0.2547 - 3s/epoch - 72ms/step\n","accuracy: 0.2547445297241211\n","loss: 1.3863762617111206\n","\n","[MODEL] VGG16_crop0.2\n","input shape: (None, 102, 173, 1)\n","43/43 - 2s - loss: 1.3864 - accuracy: 0.2518 - 2s/epoch - 41ms/step\n","accuracy: 0.25182482600212097\n","loss: 1.3863918781280518\n","\n","[MODEL] VGG16_crop0.15\n","input shape: (None, 150, 173, 1)\n","43/43 - 2s - loss: 1.3863 - accuracy: 0.2518 - 2s/epoch - 53ms/step\n","accuracy: 0.25182482600212097\n","loss: 1.386275053024292\n","\n","[MODEL] efficient_net_v2_vanilla\n","input shape: (None, 257, 173, 3)\n","43/43 - 4s - loss: 1.1026 - accuracy: 0.5861 - 4s/epoch - 86ms/step\n","accuracy: 0.5861313939094543\n","loss: 1.102561354637146\n","\n","[MODEL] efficient_net_v2_vanilla_mel\n","input shape: (None, 128, 173, 3)\n","43/43 - 3s - loss: 1.3307 - accuracy: 0.5022 - 3s/epoch - 76ms/step\n","accuracy: 0.5021897554397583\n","loss: 1.3307111263275146\n","\n"]}],"source":["x_raw ,y = make_unknown_dataset(DATA_PATH)\n","y = np_utils.to_categorical(y, 4)\n","print(\"[*INFO] Dataset bias:\", y.sum(axis=0))\n","for m in os.listdir(MODEL_PATH):\n","  print(\"[MODEL]\", pathlib.Path(m).name)\n","  try:\n","    model = keras.models.load_model(MODEL_PATH + m)\n","  except OSError:\n","    print(\"[ERROR]This model seems broken.... (> <). Pass this Evaluation.\")\n","    break\n","  s = model.input.shape\n","  print(\"input shape:\", s)\n","  x = x_raw[:,:s[1],:]\n","  try:\n","    x = x.reshape(x.shape[0], s[1], s[2], s[3])\n","  except ValueError:\n","    x_rgb = []\n","    for i in x:\n","      tmp = cv2.cvtColor(i,cv2.COLOR_GRAY2RGB)\n","      # tmp = cv2.resize(tmp,(s[1],s[2]))\n","      x_rgb.append(tmp)\n","    x = np.array(x_rgb)\n","    x = x.reshape(x.shape[0], s[1], s[2], s[3])\n","    \n","  score = model.evaluate(x, y, verbose=2)\n","\n","  print('accuracy:', score[1])\n","  print('loss:', score[0])\n","  print()\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"compare_models.ipynb","provenance":[],"mount_file_id":"1MuDm4WoMoSOYWUL6wapMR9BgjoSUnyhG","authorship_tag":"ABX9TyMLDOvYEC2rAbKkSfWg6+5u"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}